/**
 * âš¡ PullEngine - Unified Pull Engine
 *
 * Ù…Ø­Ø±Ùƒ Ø³Ø­Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Supabase Ø¥Ù„Ù‰ SQLite Ø§Ù„Ù…Ø­Ù„ÙŠ
 *
 * Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:
 * - Ø£Ø³Ù…Ø§Ø¡ Ù…ÙˆØ­Ø¯Ø© 100% Ù…Ø¹ Supabase (Ù„Ø§ TABLE_MAP)
 * - ÙÙ„ØªØ±Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ© (ØªØ¨Ø¯Ø£ Ø¨Ù€ _)
 * - Ø¯Ø¹Ù… Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„ØªÙØ§Ø¶Ù„ÙŠØ© (Delta Sync)
 * - Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© (Pending Operations)
 * - Ù…Ø²Ø§Ù…Ù†Ø© Ù…ØªÙˆØ§Ø²ÙŠØ© Ù„Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø³ØªÙ‚Ù„Ø©
 * - âš¡ ÙØ­Øµ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø´Ø¨ÙƒØ© Ù‚Ø¨Ù„ Ø§Ù„Ø¬Ù„Ø¨
 * - âš¡ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹ ØªØ£Ø®ÙŠØ± ØªØµØ§Ø¹Ø¯ÙŠ Ù„Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…Ø¤Ù‚ØªØ©
 */

import { supabase } from '@/lib/supabase-unified';
import { sqliteWriteQueue } from './SQLiteWriteQueue';
import {
    SYNCED_TABLES,
    INDEPENDENT_TABLES,
    isLocalOnlyTable,
    tableNeedsOrgId,
    getSyncTimestampField,
    getUnifiedTableName,
    addLocalSyncColumns,
    RETRY_CONFIG,
} from '../config';
import { databaseCoordinator } from './DatabaseCoordinator';
import { isAppOnline, markNetworkOffline, markNetworkOnline } from '@/utils/networkStatus';
import type { PullResult, SyncState } from '@/lib/types';

/**
 * âš¡ Ø£Ù†ÙˆØ§Ø¹ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø¨ÙƒØ©
 */
type NetworkErrorType = 'load_failed' | 'timeout' | 'network_error' | 'server_error' | 'unknown';

/**
 * âš¡ ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø®Ø·Ø£
 */
function classifyNetworkError(error: any): NetworkErrorType {
    const message = error?.message || String(error);
    
    if (message.includes('Load failed') || message.includes('Failed to fetch')) {
        return 'load_failed';
    }
    if (message.includes('timeout') || message.includes('AbortError')) {
        return 'timeout';
    }
    if (message.includes('network') || message.includes('Network')) {
        return 'network_error';
    }
    if (error?.code === 'PGRST' || message.includes('500') || message.includes('503')) {
        return 'server_error';
    }
    return 'unknown';
}

/**
 * âš¡ Ù‡Ù„ Ø§Ù„Ø®Ø·Ø£ Ù‚Ø§Ø¨Ù„ Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©ØŸ
 */
function isRetryableError(errorType: NetworkErrorType): boolean {
    return ['load_failed', 'timeout', 'network_error', 'server_error'].includes(errorType);
}

/**
 * âš¡ ØªØ£Ø®ÙŠØ± Ù…Ø¹ exponential backoff
 */
async function delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
}

/**
 * âš¡ Ø­Ø³Ø§Ø¨ ÙˆÙ‚Øª Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù„Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©
 */
function getRetryDelay(attempt: number): number {
    const baseDelay = RETRY_CONFIG.BASE_DELAY_MS;
    const maxDelay = RETRY_CONFIG.MAX_DELAY_MS;
    const factor = RETRY_CONFIG.EXPONENTIAL_FACTOR;
    
    const calculatedDelay = baseDelay * Math.pow(factor, attempt - 1);
    return Math.min(calculatedDelay, maxDelay);
}

/**
 * âš¡ PullEngine Configuration
 */
interface PullEngineConfig {
    batchSize: number;
    maxParallel: number;
    enableSmartBatching: boolean; // âš¡ CRITICAL FIX: Smart Batching Ù„Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„Ø¹Ù…Ù„ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©
}

const DEFAULT_CONFIG: PullEngineConfig = {
    batchSize: 1000,
    maxParallel: 5,
    enableSmartBatching: true,
};

/**
 * âš¡ CRITICAL FIX: Ø¬Ø¯Ø§ÙˆÙ„ Ø­Ø±Ø¬Ø© ÙŠØ¬Ø¨ Ù…Ø²Ø§Ù…Ù†ØªÙ‡Ø§ Ø£ÙˆÙ„Ø§Ù‹ Ù‚Ø¨Ù„ Ø§Ù„Ø³Ù…Ø§Ø­ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø§Ù„Ø¹Ù…Ù„
 * Ù‡Ø°Ù‡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¶Ø±ÙˆØ±ÙŠØ© Ù„Ù„Ø¹Ù…Ù„ Ø§Ù„ÙŠÙˆÙ…ÙŠ (POS, Inventory, etc.)
 */
const CRITICAL_TABLES = [
    'products',
    'product_categories',
    'customers',
    'orders',
] as const;

/**
 * âš¡ Ø¬Ø¯Ø§ÙˆÙ„ ØºÙŠØ± Ø­Ø±Ø¬Ø© ÙŠÙ…ÙƒÙ† Ù…Ø²Ø§Ù…Ù†ØªÙ‡Ø§ ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø­Ø±Ø¬Ø©
 */
function isCriticalTable(tableName: string): boolean {
    return CRITICAL_TABLES.includes(tableName as any);
}

/**
 * âš¡ PullEngine Class
 */
export class PullEngine {
    private organizationId: string;
    private pendingIds: Map<string, Set<string>> = new Map();
    private config: PullEngineConfig;

    constructor(organizationId: string, config: Partial<PullEngineConfig> = {}) {
        this.organizationId = organizationId;
        this.config = { ...DEFAULT_CONFIG, ...config };
    }

    /**
     * âš¡ Initialize the engine
     */
    async init(): Promise<void> {
        // Create sync_state table if not exists
        await sqliteWriteQueue.write(`
            CREATE TABLE IF NOT EXISTS sync_state (
                table_name TEXT PRIMARY KEY,
                last_synced_at TEXT,
                last_sync_status TEXT,
                error_message TEXT
            )
        `);

        // Load pending operations cache
        await this.refreshPendingCache();
    }

    /**
     * âš¡ Refresh the cache of pending operations
     */
    async refreshPendingCache(): Promise<void> {
        try {
            const pending = await sqliteWriteQueue.read<any[]>(`
                SELECT table_name, record_id FROM sync_outbox
                WHERE status IN ('pending', 'sending')
            `);

            this.pendingIds.clear();
            for (const op of pending) {
                if (!this.pendingIds.has(op.table_name)) {
                    this.pendingIds.set(op.table_name, new Set());
                }
                this.pendingIds.get(op.table_name)!.add(op.record_id);
            }

            console.log(`[PullEngine] ğŸ“‹ Cached ${pending.length} pending operations`);
        } catch (error) {
            console.warn('[PullEngine] âš ï¸ Failed to refresh pending cache:', error);
        }
    }

    /**
     * âš¡ Clear the pending cache
     */
    clearCache(): void {
        this.pendingIds.clear();
    }

    /**
     * âš¡ Pull all synced tables
     * 
     * âš ï¸ CRITICAL FIX: Smart Batching Ù„Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„Ø¹Ù…Ù„ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©
     * - Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø­Ø±Ø¬Ø© ØªÙØ²Ø§Ù…Ù† Ø£ÙˆÙ„Ø§Ù‹ (products, orders, customers)
     * - Ø¨Ø¹Ø¯Ù‡Ø§ ÙŠÙ…ÙƒÙ† Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨Ø¯Ø¡ Ø¨Ø§Ù„Ø¹Ù…Ù„
     * - Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ØºÙŠØ± Ø§Ù„Ø­Ø±Ø¬Ø© ØªÙØ²Ø§Ù…Ù† ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©
     */
    async pullAll(): Promise<Map<string, PullResult>> {
        console.log('[PullEngine] ğŸ”„ Starting full pull...');

        await this.refreshPendingCache();

        const results = new Map<string, PullResult>();

        if (this.config.enableSmartBatching) {
            // âš¡ Smart Batching: ÙØµÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø­Ø±Ø¬Ø© Ø¹Ù† ØºÙŠØ± Ø§Ù„Ø­Ø±Ø¬Ø©
            const allTables = SYNCED_TABLES as unknown as string[];
            const criticalTables: string[] = [];
            const nonCriticalTables: string[] = [];

            for (const table of allTables) {
                if (isCriticalTable(table)) {
                    criticalTables.push(table);
                } else {
                    nonCriticalTables.push(table);
                }
            }

            console.log(`[PullEngine] âš¡ Smart Batching: ${criticalTables.length} critical, ${nonCriticalTables.length} non-critical`);

            // 1ï¸âƒ£ Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø­Ø±Ø¬Ø© Ø£ÙˆÙ„Ø§Ù‹ (ÙŠØ¬Ø¨ Ø¥ÙƒÙ…Ø§Ù„Ù‡Ø§ Ù‚Ø¨Ù„ Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„Ø¹Ù…Ù„)
            console.log('[PullEngine] ğŸ”´ Phase 1: Syncing critical tables...');
            const criticalResults = await this.pullTablesParallel(criticalTables);
            criticalResults.forEach((result, table) => results.set(table, result));

            // âš¡ Ø¥Ø´Ø¹Ø§Ø± Ø£Ù† Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø­Ø±Ø¬Ø© Ø§ÙƒØªÙ…Ù„Øª - ÙŠÙ…ÙƒÙ† Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨Ø¯Ø¡ Ø¨Ø§Ù„Ø¹Ù…Ù„
            const criticalProcessed = Array.from(criticalResults.values()).reduce((sum, r) => sum + r.processed, 0);
            const criticalErrors = Array.from(criticalResults.values()).reduce((sum, r) => sum + r.errors, 0);
            console.log(
                `[PullEngine] âœ… Critical tables complete: ${criticalProcessed} processed, ${criticalErrors} errors. ` +
                `User can start working. Background sync continuing...`
            );

            // 2ï¸âƒ£ Ù…Ø²Ø§Ù…Ù†Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ØºÙŠØ± Ø§Ù„Ø­Ø±Ø¬Ø© ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© (Ù„Ø§ ØªÙ…Ù†Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ø§Ù„Ø¹Ù…Ù„)
            if (nonCriticalTables.length > 0) {
                console.log('[PullEngine] ğŸŸ¢ Phase 2: Syncing non-critical tables in background...');
                // âš¡ Ø§Ø³ØªØ®Ø¯Ø§Ù… setTimeout Ù„Ù„Ø³Ù…Ø§Ø­ Ù„Ù„Ù…ØªØµÙØ­ Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
                const backgroundSync = async () => {
                    // ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ØºÙŠØ± Ø§Ù„Ø­Ø±Ø¬Ø© Ø¥Ù„Ù‰ batches ØµØºÙŠØ±Ø© Ù„ØªØ¬Ù†Ø¨ Ø­Ø¬Ø¨ UI
                    const batchSize = 3;
                    for (let i = 0; i < nonCriticalTables.length; i += batchSize) {
                        const batch = nonCriticalTables.slice(i, i + batchSize);
                        const batchResults = await this.pullTablesParallel(batch);
                        batchResults.forEach((result, table) => results.set(table, result));

                        // âš¡ Yield Ù„Ù„Ø³Ù…Ø§Ø­ Ù„Ù„Ù…ØªØµÙØ­ Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
                        await new Promise(resolve => setTimeout(resolve, 0));
                    }
                    console.log('[PullEngine] âœ… Background sync complete');
                };

                // âš¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© Ø¨Ø¯ÙˆÙ† Ø§Ù†ØªØ¸Ø§Ø±
                backgroundSync().catch(error => {
                    console.error('[PullEngine] âŒ Background sync error:', error);
                });
            }
        } else {
            // âš¡ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù‚Ø¯ÙŠÙ…: Ù…Ø²Ø§Ù…Ù†Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¨Ø§Ù„ØªØ³Ù„Ø³Ù„
            const independentResults = await this.pullTablesParallel(
                INDEPENDENT_TABLES as unknown as string[]
            );
            independentResults.forEach((result, table) => results.set(table, result));

            const processedTables = new Set(INDEPENDENT_TABLES);
            const remainingTables = SYNCED_TABLES.filter(t => !processedTables.has(t as any));

            for (const table of remainingTables) {
                const result = await this.pullTable(table);
                results.set(table, result);
            }
        }

        return results;
    }

    /**
     * âš¡ Pull multiple tables in parallel
     */
    async pullTablesParallel(tableNames: string[]): Promise<Map<string, PullResult>> {
        const results = new Map<string, PullResult>();

        // âš¡ CRITICAL: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø©
        if (databaseCoordinator.isSyncPaused()) {
            console.log('[PullEngine] â¸ï¸ Sync paused, skipping parallel pull');
            return results;
        }

        // Split into chunks to respect maxParallel
        const chunks: string[][] = [];
        for (let i = 0; i < tableNames.length; i += this.config.maxParallel) {
            chunks.push(tableNames.slice(i, i + this.config.maxParallel));
        }

        for (const chunk of chunks) {
            // âš¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù‚Ø¨Ù„ ÙƒÙ„ chunk
            if (databaseCoordinator.isSyncPaused()) {
                console.log('[PullEngine] â¸ï¸ Sync paused during chunk processing');
                break;
            }

            const chunkResults = await Promise.all(
                chunk.map(table => this.pullTable(table))
            );

            chunk.forEach((table, index) => {
                results.set(table, chunkResults[index]);
            });
        }

        return results;
    }

    /**
     * âš¡ Pull a single table with retry logic
     */
    async pullTable(tableName: string): Promise<PullResult> {
        const startTime = Date.now();
        const result: PullResult = { processed: 0, skipped: 0, errors: 0 };

        // âš¡ CRITICAL: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø²Ø§Ù…Ù†Ø© Ø¨ÙˆØ§Ø³Ø·Ø© DatabaseCoordinator
        if (databaseCoordinator.isSyncPaused()) {
            console.log(`[PullEngine] â¸ï¸ Sync paused, skipping table: ${tableName}`);
            return result;
        }

        // âš¡ CRITICAL: ÙØ­Øµ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø´Ø¨ÙƒØ© Ù‚Ø¨Ù„ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¬Ù„Ø¨
        if (!isAppOnline()) {
            console.log(`[PullEngine] ğŸ“´ Offline, skipping table: ${tableName}`);
            return result;
        }

        // Get unified table name (for legacy support)
        const unifiedTableName = getUnifiedTableName(tableName);

        // Skip local-only tables
        if (isLocalOnlyTable(unifiedTableName)) {
            console.log(`[PullEngine] â­ï¸ Skipping local-only table: ${unifiedTableName}`);
            return result;
        }

        try {
            const syncState = await this.getSyncState(unifiedTableName);
            const lastSynced = syncState?.last_synced_at || '1970-01-01T00:00:00Z';
            const timestampField = getSyncTimestampField(unifiedTableName);

            console.log(`[PullEngine] â¬‡ï¸ Pulling ${unifiedTableName} since ${lastSynced}`);

            // Get pending IDs for this table
            const pendingIds = this.pendingIds.get(tableName) || this.pendingIds.get(unifiedTableName) || new Set();

            let page = 0;
            let hasMore = true;
            let maxTimestamp = lastSynced;

            while (hasMore) {
                // âš¡ Ø¥Ø¹Ø§Ø¯Ø© ÙØ­Øµ Ø§Ù„Ø´Ø¨ÙƒØ© Ù‚Ø¨Ù„ ÙƒÙ„ ØµÙØ­Ø©
                if (!isAppOnline()) {
                    console.log(`[PullEngine] ğŸ“´ Connection lost during pull, stopping: ${unifiedTableName}`);
                    break;
                }

                // âš¡ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
                const fetchResult = await this.fetchTablePageWithRetry(
                    unifiedTableName,
                    timestampField,
                    lastSynced,
                    page
                );

                if (fetchResult.error) {
                    const errorType = classifyNetworkError(fetchResult.error);
                    console.error(`[PullEngine] âŒ Error fetching ${unifiedTableName} (${errorType}):`, fetchResult.error);
                    
                    // âš¡ ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø´Ø¨ÙƒØ© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø®Ø·Ø£ Ø´Ø¨ÙƒØ©
                    if (errorType === 'load_failed' || errorType === 'network_error') {
                        markNetworkOffline();
                    }
                    
                    result.errors++;
                    break;
                }

                const data = fetchResult.data;

                if (!data || data.length === 0) {
                    hasMore = false;
                    break;
                }

                // Process records
                const toUpsert: any[] = [];
                const toDelete: string[] = [];

                for (const record of data as any[]) {
                    // Skip pending records (local wins)
                    const recordId = record?.id;
                    if (recordId && pendingIds.has(recordId)) {
                        result.skipped++;
                        continue;
                    }

                    // Handle soft delete
                    if (record?.deleted_at) {
                        if (recordId) {
                            toDelete.push(recordId);
                        }
                    } else {
                        // âš¡ CRITICAL FIX: Ø¬Ø¯Ø§ÙˆÙ„ Ù…Ø®ØªÙ„ÙØ© ØªØ³ØªØ®Ø¯Ù… Ø£Ù†Ù…Ø§Ø· Ø£Ø¹Ù…Ø¯Ø© Ù…Ø®ØªÙ„ÙØ©
                        // - orders, order_items, staff_work_sessions ØªØ³ØªØ®Ø¯Ù…: synced, sync_status, pending_operation (Ø¨Ø¯ÙˆÙ† underscore)
                        // - Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ØªØ³ØªØ®Ø¯Ù…: _synced, _sync_status, _pending_operation (Ù…Ø¹ underscore)
                        const TABLES_WITHOUT_UNDERSCORE = ['orders', 'order_items', 'staff_work_sessions'];
                        const usesUnderscorePrefix = !TABLES_WITHOUT_UNDERSCORE.includes(unifiedTableName);
                        
                        let localRecord: any;
                        if (usesUnderscorePrefix) {
                            // Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… underscore prefix
                            localRecord = {
                                ...record,
                                _synced: 1,
                                _sync_status: 'synced',
                                _pending_operation: null as any,
                                _local_updated_at: new Date().toISOString(),
                            };
                        } else {
                            // âš¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØªÙŠ Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… underscore prefix (orders, order_items, staff_work_sessions)
                            localRecord = {
                                ...record,
                                synced: 1,
                                sync_status: 'synced',
                                pending_operation: null as any,
                            };
                        }
                        
                        toUpsert.push(localRecord);
                    }

                    // Track max timestamp
                    const recordTimestamp = record[timestampField];
                    if (recordTimestamp && recordTimestamp > maxTimestamp) {
                        maxTimestamp = recordTimestamp;
                    }
                }

                // Apply deletes
                if (toDelete.length > 0) {
                    await this.deleteRecords(unifiedTableName, toDelete);
                    result.processed += toDelete.length;
                }

                // Apply upserts
                if (toUpsert.length > 0) {
                    await this.upsertRecords(unifiedTableName, toUpsert);
                    result.processed += toUpsert.length;
                }

                // Check if more pages
                if (data.length < this.config.batchSize) {
                    hasMore = false;
                } else {
                    page++;
                }
            }

            // Update sync state
            if (result.errors === 0) {
                await this.updateSyncState(unifiedTableName, maxTimestamp, 'success');
            }

            const duration = Date.now() - startTime;
            console.log(
                `[PullEngine] âœ… ${unifiedTableName}: ${result.processed} processed, ` +
                `${result.skipped} skipped, ${result.errors} errors (${duration}ms)`
            );

        } catch (error: any) {
            console.error(`[PullEngine] âŒ Critical error pulling ${unifiedTableName}:`, error);
            result.errors++;
            await this.updateSyncState(unifiedTableName, null, 'error', error.message);
        }

        return result;
    }

    /**
     * âš¡ Fetch a page of data with retry logic
     */
    private async fetchTablePageWithRetry(
        tableName: string,
        timestampField: string,
        lastSynced: string,
        page: number
    ): Promise<{ data: any[] | null; error: any }> {
        const maxAttempts = RETRY_CONFIG.MAX_ATTEMPTS;
        let lastError: any = null;

        for (let attempt = 1; attempt <= maxAttempts; attempt++) {
            // âš¡ ÙØ­Øµ Ø§Ù„Ø´Ø¨ÙƒØ© Ù‚Ø¨Ù„ ÙƒÙ„ Ù…Ø­Ø§ÙˆÙ„Ø©
            if (!isAppOnline()) {
                console.log(`[PullEngine] ğŸ“´ Offline, aborting retry for ${tableName}`);
                return { data: null, error: new Error('Network offline') };
            }

            try {
                // Build query
                const queryBuilder = supabase.from(tableName as any) as any;
                let query = queryBuilder
                    .select('*')
                    .gt(timestampField, lastSynced)
                    .order(timestampField, { ascending: true })
                    .range(page * this.config.batchSize, (page + 1) * this.config.batchSize - 1);

                // Add organization filter if needed
                if (tableNeedsOrgId(tableName)) {
                    query = query.eq('organization_id', this.organizationId);
                }

                const { data, error } = await query;

                if (error) {
                    lastError = error;
                    const errorType = classifyNetworkError(error);

                    // âš¡ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø·Ø£ Ù‚Ø§Ø¨Ù„ Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
                    if (isRetryableError(errorType) && attempt < maxAttempts) {
                        const retryDelay = getRetryDelay(attempt);
                        console.log(
                            `[PullEngine] ğŸ”„ Retry ${attempt}/${maxAttempts} for ${tableName} ` +
                            `(${errorType}), waiting ${retryDelay}ms...`
                        );
                        await delay(retryDelay);
                        continue;
                    }

                    // âš¡ Ø®Ø·Ø£ ØºÙŠØ± Ù‚Ø§Ø¨Ù„ Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø£Ùˆ Ù†ÙØ¯Øª Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª
                    return { data: null, error };
                }

                // âš¡ Ù†Ø¬Ø§Ø­! ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø´Ø¨ÙƒØ©
                markNetworkOnline();
                return { data, error: null };

            } catch (error: any) {
                lastError = error;
                const errorType = classifyNetworkError(error);

                console.warn(
                    `[PullEngine] âš ï¸ Attempt ${attempt}/${maxAttempts} failed for ${tableName}:`,
                    { type: errorType, message: error?.message }
                );

                // âš¡ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø·Ø£ Ù‚Ø§Ø¨Ù„ Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
                if (isRetryableError(errorType) && attempt < maxAttempts) {
                    const retryDelay = getRetryDelay(attempt);
                    console.log(`[PullEngine] ğŸ”„ Retrying in ${retryDelay}ms...`);
                    await delay(retryDelay);
                    continue;
                }

                // âš¡ Ø®Ø·Ø£ ØºÙŠØ± Ù‚Ø§Ø¨Ù„ Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø£Ùˆ Ù†ÙØ¯Øª Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª
                break;
            }
        }

        // âš¡ ÙØ´Ù„Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª
        console.error(`[PullEngine] âŒ All ${maxAttempts} attempts failed for ${tableName}`);
        return { data: null, error: lastError || new Error('All retry attempts failed') };
    }

    /**
     * âš¡ Delete records from local database
     */
    private async deleteRecords(tableName: string, ids: string[]): Promise<void> {
        if (ids.length === 0) return;

        const placeholders = ids.map(() => '?').join(',');
        await sqliteWriteQueue.write(
            `DELETE FROM ${tableName} WHERE id IN (${placeholders})`,
            ids
        );
    }

    /**
     * âš¡ Upsert records to local database
     */
    private async upsertRecords(tableName: string, records: any[]): Promise<void> {
        if (records.length === 0) return;
        
        // âš¡ CRITICAL FIX: ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù… Ø£Ø¹Ù…Ø¯Ø© Ø¨Ø¯ÙˆÙ† underscore
        const TABLES_WITHOUT_UNDERSCORE = ['orders', 'order_items', 'staff_work_sessions', 'products'];
        const usesUnderscorePrefix = !TABLES_WITHOUT_UNDERSCORE.includes(tableName);
        
        // âš¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªÙŠ ÙŠØ¬Ø¨ ØªØ¬Ø§Ù‡Ù„Ù‡Ø§ Ù„Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØªÙŠ Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… underscore
        const UNDERSCORE_SYNC_COLUMNS = ['_synced', '_sync_status', '_pending_operation', '_local_updated_at', '_error'];

        for (const record of records) {
            // âš¡ Map columns to match database schema
            const mappedRecord: Record<string, any> = {};
            
            for (const [key, value] of Object.entries(record)) {
                // âš¡ CRITICAL FIX: Ù„Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØªÙŠ Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… underscore prefix
                // ÙŠØ¬Ø¨ ØªØ¬Ø§Ù‡Ù„ Ø¬Ù…ÙŠØ¹ Ø£Ø¹Ù…Ø¯Ø© underscore sync
                if (!usesUnderscorePrefix && UNDERSCORE_SYNC_COLUMNS.includes(key)) {
                    // ØªØ­ÙˆÙŠÙ„ _synced Ø¥Ù„Ù‰ synced Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ Ø¨Ø§Ù„ÙØ¹Ù„
                    if (key === '_synced' && !('synced' in record)) {
                        mappedRecord['synced'] = value ? 1 : 0;
                    }
                    // ØªØ¬Ø§Ù‡Ù„ Ø¨Ø§Ù‚ÙŠ Ø£Ø¹Ù…Ø¯Ø© underscore
                    continue;
                }
                
                // âš¡ Filter out _customer_name_lower for orders if column doesn't exist
                // (The column should exist per schema, but handle gracefully if migration hasn't run)
                if (key === '_customer_name_lower' && tableName === 'orders') {
                    // Keep it - the column should exist per schema
                    mappedRecord[key] = value;
                    continue;
                }
                
                // âš¡ Convert arrays and objects to JSON strings
                if (Array.isArray(value) || (typeof value === 'object' && value !== null && value !== undefined)) {
                    mappedRecord[key] = JSON.stringify(value);
                } else {
                    mappedRecord[key] = value;
                }
            }

            // Get column names and values
            const columns = Object.keys(mappedRecord);
            const values = columns.map(col => mappedRecord[col]);
            const placeholders = columns.map(() => '?').join(',');

            try {
                await sqliteWriteQueue.write(
                    `INSERT OR REPLACE INTO ${tableName} (${columns.join(',')}) VALUES (${placeholders})`,
                    values
                );
            } catch (error: any) {
                // âš¡ Handle missing column errors gracefully
                if (error?.message?.includes('no column named')) {
                    const columnMatch = error.message.match(/no column named (\w+)/);
                    if (columnMatch) {
                        const missingColumn = columnMatch[1];
                        console.warn(`[PullEngine] âš ï¸ Column ${missingColumn} doesn't exist in ${tableName}, filtering it out`);
                        
                        // Retry without the missing column
                        const filteredColumns = columns.filter(col => col !== missingColumn);
                        const filteredValues = filteredColumns.map(col => mappedRecord[col]);
                        const filteredPlaceholders = filteredColumns.map(() => '?').join(',');
                        
                        await sqliteWriteQueue.write(
                            `INSERT OR REPLACE INTO ${tableName} (${filteredColumns.join(',')}) VALUES (${filteredPlaceholders})`,
                            filteredValues
                        );
                        continue;
                    }
                }
                throw error;
            }
        }
    }

    /**
     * âš¡ Get sync state for a table
     */
    private async getSyncState(tableName: string): Promise<SyncState | null> {
        try {
            const result = await sqliteWriteQueue.read<SyncState[]>(
                `SELECT * FROM sync_state WHERE table_name = ?`,
                [tableName]
            );
            return result[0] || null;
        } catch {
            return null;
        }
    }

    /**
     * âš¡ Update sync state for a table
     */
    private async updateSyncState(
        tableName: string,
        lastSynced: string | null,
        status: 'success' | 'error',
        errorMessage?: string
    ): Promise<void> {
        await sqliteWriteQueue.write(
            `INSERT OR REPLACE INTO sync_state (table_name, last_synced_at, last_sync_status, error_message)
             VALUES (?, ?, ?, ?)`,
            [tableName, lastSynced, status, errorMessage || null]
        );
    }

    /**
     * âš¡ Reset sync state for specific tables (forces full re-sync)
     * ÙŠÙØ³ØªØ®Ø¯Ù… Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø²Ø§Ù…Ù†Ø© Ø¬Ø¯Ø§ÙˆÙ„ Ù…Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
     */
    async resetSyncState(tableNames: string[]): Promise<void> {
        for (const tableName of tableNames) {
            const unifiedName = getUnifiedTableName(tableName);
            console.log(`[PullEngine] ğŸ”„ Resetting sync state for: ${unifiedName}`);
            await sqliteWriteQueue.write(
                `DELETE FROM sync_state WHERE table_name = ?`,
                [unifiedName]
            );
        }
    }

    /**
     * âš¡ Reset sync state for all tables
     */
    async resetAllSyncState(): Promise<void> {
        console.log('[PullEngine] ğŸ”„ Resetting ALL sync states...');
        await sqliteWriteQueue.write(`DELETE FROM sync_state`);
    }

    /**
     * âš¡ CRITICAL FIX: Pull only critical tables (for fast startup)
     * ÙŠÙØ³ØªØ®Ø¯Ù… Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø¹Ù…Ù„ Ø¨Ø³Ø±Ø¹Ø© Ø¯ÙˆÙ† Ø§Ù†ØªØ¸Ø§Ø± Ù…Ø²Ø§Ù…Ù†Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
     */
    async pullCriticalOnly(): Promise<Map<string, PullResult>> {
        console.log('[PullEngine] ğŸ”´ Pulling critical tables only...');

        await this.refreshPendingCache();

        const results = new Map<string, PullResult>();
        const criticalTables = (SYNCED_TABLES as unknown as string[]).filter(isCriticalTable);

        const criticalResults = await this.pullTablesParallel(criticalTables);
        criticalResults.forEach((result, table) => results.set(table, result));

        const totalProcessed = Array.from(criticalResults.values()).reduce((sum, r) => sum + r.processed, 0);
        const totalErrors = Array.from(criticalResults.values()).reduce((sum, r) => sum + r.errors, 0);
        console.log(
            `[PullEngine] âœ… Critical tables complete: ${totalProcessed} processed, ${totalErrors} errors`
        );

        return results;
    }
}
